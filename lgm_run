#!/usr/bin/env python3

import sys
import os
import click
import subprocess as sp
import time
import signal
import atexit

script_dir = os.path.dirname(os.path.realpath(__file__))
manager_def = os.path.join(script_dir, "manager_tcp")
manager_proc = None
login = None
ava_ip = 'localhost'


def clean_up():
    if manager_proc:
        manager_proc.send_signal(signal.SIGINT)
        os.system('ssh {} killall -9 worker manager_tcp &>/dev/null'.format(login))
atexit.register(clean_up)

def run_test(test_cmd):
    try:
        print("Running test")
        return sp.run(test_cmd, env=ava_env_client()).returncode
    except Exception as e:
        print("ERROR:", e);
        sys.exit(1)

guest_lib=os.path.join(script_dir, 'libguestlib.so')
shim=os.path.join(script_dir, 'guestshim.so')

extra_client_env = {
    'LD_PRELOAD'  : ':'.join([shim, guest_lib]),
    'AVA_LOCAL'   : '1',
    'HCC_LAZYINIT': '1',
    'HIP_ENABLE_COMMAND_SCHEDULER' : '0',
}

def ava_env_client():
    new_env = dict(os.environ)
    new_env['AVA_IP'] = ava_ip
    new_env.update(extra_client_env)
    return new_env

@click.command()
@click.argument('run-type', type=click.Choice(['baseline','ava']))
@click.argument('test-cmd', nargs=-1)
@click.option('--server', default=manager_def)
@click.option('--gpu-op-batch-size', default=64)
@click.option('--gpu-op-batching/--no-gpu-op-batching', default=False)
def main(run_type, test_cmd, server, gpu_op_batching, gpu_op_batch_size):
    global ava_ip
    if len(test_cmd) == 0:
        print("no command given exiting!")
        sys.exit(1)
    if server:
        ava_ip = server
    if gpu_op_batching:
        extra_client_env["HIP_ENABLE_COMMAND_SCHEDULER"] = "1"
        extra_client_env["HIP_COMMAND_SCHEDULER_BATCH_SIZE"] = str(gpu_op_batch_size)
    sys.exit(run_test(test_cmd))

if __name__ == '__main__':
    main()
